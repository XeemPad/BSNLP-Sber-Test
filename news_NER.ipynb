{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5830d50b",
   "metadata": {},
   "source": [
    "# Тестовое задание в команду Data Science IDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e15620",
   "metadata": {},
   "source": [
    "Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8128a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f284dc0",
   "metadata": {},
   "source": [
    "## Формулировка задания"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceb0370",
   "metadata": {},
   "source": [
    "**Написать решение по извлечению сущностей из документов (новостных текстов)**\n",
    "\n",
    "**Датасет** -- семпл текстов с аннотациями русских новостей (источник: https://bsnlp.cs.helsinki.fi/bsnlp-2019/shared_task.html)\n",
    "\n",
    "**Интересующие сущности:**\n",
    "- *PER* - persons (личности)\n",
    "- *ORG* - organizations (организации)\n",
    "- *LOC* - locations (места)\n",
    "- *EVT* - events (события)\n",
    "- *PRO* - products (продукты и документы)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f9de87",
   "metadata": {},
   "source": [
    "Достаточно использовать *9 документов* про *брекзит* из семпла"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d61960",
   "metadata": {},
   "source": [
    "## Задание 1 (Анализ задачи)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37be8b1",
   "metadata": {},
   "source": [
    "**Описание задачи с точки зрения NLP**\n",
    "\n",
    "Это задача извлечения именованных сущностей из текст -- *Named Entity Recognition (NER)*. В данном случае мы занимаемся последовательной разметкой, классифицируя каждый токен как PER, ORG, LOC, EVT, PRO или не являющийся сущностью\n",
    "\n",
    "**Классические методы решения:**\n",
    "- Статистические методы: *Условные случайные поля (CRF)*, *Марковская модель максимальной энтропии (MEMM)*\n",
    "- Рекуррентные нейронные сети: *LSTM*, *BiLSTM* (часто с CRF слоем)\n",
    "- Энкодерные трансформеры: *BERT-like*\n",
    "\n",
    "**LLM методы:**\n",
    "- *Zero-shot/Few-shot* подходы (GPT, в т.ч. *GigaChat*)\n",
    "- Промты с инструкциями для GPT-моделей\n",
    "- *Fine-tuning* на обучающей выборке\n",
    "- *Chain-of-Thought (CoT)* промпты для размышления перед определением сущности\n",
    "\n",
    "**Метрики качества:**\n",
    "- *Precision, Recall и F1-score* для найденных сущностей (верные границы), **без учета типа сущности**\n",
    "- *Precision, Recall и F1-score* для **точного совпадения** (границы + тип сущности)\n",
    "- Эти же метрики с *частичным совпадением границ*\n",
    "- Эти же метрики для каждого отдельного класса (для выявления, с какими типами сущностей у модели проблемы). Macro-F1 (усреднённый по классам)\n",
    "\n",
    "- Можно добавить *accuracy* лемматизации каждой верно найденной сущности (для задачи из оригинального соревнования)\n",
    "- *Inference time* (в данном случае зависит от провайдера GigaChat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e51aea1",
   "metadata": {},
   "source": [
    "## Задание 2 (Формирование DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd1dcc1",
   "metadata": {},
   "source": [
    "### Чтение датасета в pandas DataFrame с обязательными колонками \"document_id\", \"document_text\", \"entity\", \"gold_answer\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578b9bee",
   "metadata": {},
   "source": [
    "#### Функция для извлечения данных и формирования DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e4d52ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bsnlp_data(data_dir: str='sample_pl_cs_ru_bg', lang: str=\"ru\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Считывание данных соревнования из папок raw/ru и annotated/ru и преобразует в\n",
    "    требуемый формат pd.DataFrame: [\"document_id\", \"document_text\", \"entity\", \"gold_answer\"]\n",
    "    \"\"\"\n",
    "    raw_dir = pathlib.Path(data_dir) / 'raw' / lang\n",
    "    annotated_dir = pathlib.Path(data_dir) / 'annotated' / lang\n",
    "\n",
    "    documents_desc: List[dict] = []\n",
    "\n",
    "    # Raw файлы\n",
    "    for raw_file in raw_dir.glob('*.txt'):\n",
    "        with open(raw_file, encoding=\"utf-8\") as f:\n",
    "            lines: List[str] = f.readlines()\n",
    "\n",
    "        assert len(lines) >= 5, f\"File \\\"{str(raw_file)}\\\" contains less than 5 lines\"\n",
    "\n",
    "        document_id = lines[0].strip()\n",
    "        language = lines[1].strip()\n",
    "        date = lines[2].strip()\n",
    "        url = lines[3].strip()\n",
    "        title = lines[4].strip()\n",
    "        content = ' '.join([line.strip() for line in lines[5:] if line.strip()])\n",
    "        document_text = title + ' ' + content\n",
    "\n",
    "        # Ищем соответствующий аннотированный файл\n",
    "        annotation_file = annotated_dir / f\"{raw_file.stem}.out\"\n",
    "\n",
    "        assert annotation_file.exists(), \\\n",
    "            f\"Annotation file \\\"{str(annotation_file)}\\\" corresponding to raw file \\\"{str(raw_file)}\\\" does not exist\"\n",
    "        \n",
    "        # Читаем аннотации\n",
    "        with open(annotation_file, encoding='utf-8') as f:\n",
    "            annotation_lines = f.readlines()\n",
    "\n",
    "        assert len(annotation_lines) > 0, f\"Annotation file \\\"{str(annotation_file)}\\\" is empty\"\n",
    "        annotation_doc_id = annotation_lines[0].strip()\n",
    "\n",
    "        assert document_id == annotation_doc_id, \"Raw and Annotated doc ids do not match: \" \\\n",
    "                                                f\"{document_id}, {annotation_doc_id}\"\n",
    "\n",
    "        entities_found = []\n",
    "\n",
    "        for line in annotation_lines[1:]:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                columns = line.split('\\t')\n",
    "                assert len(columns) == 4\n",
    "\n",
    "                entity_text, entity_text_lemmatized, entity_type, entity_id = columns\n",
    "\n",
    "                entities_found.append( (entity_text, entity_type) )\n",
    "        \n",
    "        for entity_text, entity_type in entities_found:\n",
    "            documents_desc.append({\n",
    "                'document_id': document_id,\n",
    "                'document_text': document_text,\n",
    "                'entity': entity_text,\n",
    "                'gold_answer': entity_type\n",
    "            })\n",
    "        if not entities_found:\n",
    "            documents_desc.append({\n",
    "                'document_id': document_id,\n",
    "                'document_text': document_text,\n",
    "                'entity': None,\n",
    "                'gold_answer': None\n",
    "            })\n",
    "        \n",
    "    return pd.DataFrame(documents_desc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96d312",
   "metadata": {},
   "source": [
    "#### Просмотр данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6516a236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_text</th>\n",
       "      <th>entity</th>\n",
       "      <th>gold_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>EVT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Альбиона</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Альбионе</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Борис Джонсон</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Британии</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  document_id                                      document_text  \\\n",
       "0       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "1       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "2       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "3       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "4       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "\n",
       "          entity gold_answer  \n",
       "0         Brexit         EVT  \n",
       "1       Альбиона         LOC  \n",
       "2       Альбионе         LOC  \n",
       "3  Борис Джонсон         PER  \n",
       "4       Британии         LOC  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_bsnlp_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30053db4",
   "metadata": {},
   "source": [
    "## Задание 3 (Функция для преобразования строки из DataFrame в запрос для LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a04ab307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_for_llm(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Создает промпт для LLM на основе строки датафрейма\n",
    "    \"\"\"\n",
    "    document_text = row['document_text']\n",
    "    \n",
    "    prompt = f\"\"\"Извлеки из **текста для анализа** все (необязательно уникальные) именованные сущности и классифицируй их по типам, опираясь на контекст и нижеуказанные инструкции.\n",
    "\n",
    "**Типы сущностей:**\n",
    "- PER (persons) - личности, имена людей (без прилежащих титулов), группы людей (\"русские\"; НО НЕ \"мусульмане\", т.к. нет конкретной объединяющей организации)\n",
    "- ORG (organizations) - организации, компании, учреждения, объединения\n",
    "- LOC (locations) - географические места, страны, города\n",
    "- EVT (events) - события, процессы, явления\n",
    "- PRO (products) - продукты, документы, произведения\n",
    "\n",
    "**Если равновероятными кажутся типы:**\n",
    "- ORG и PER, то должно быть выбрано PER;\n",
    "- ORG и PRO, то должно быть выбрано ORG.\n",
    "\n",
    "**Замечания:**\n",
    "- Сохраняй точную форму, регистр слов и количество вхождений сущностей как в оригинальном тексте. \n",
    "То есть, если сущность встречается в нескольких формах (Москва, Москвы), каждая форма должна быть в ответе.\n",
    "Однако одинаковые формы (Москва, Москва) повторять не надо.\n",
    "- Текст \"Премьер-министр Великобритании Тереза Мэй\" содержит LOC (Великобритании) и PER (Тереза Мэй)\n",
    "- Текст \"Церковь Св. Стефана в Стамбуле\" является целиком одной сущностью типа LOC\n",
    "- Расположение организации ORG и события EVT является частью их сущности (\"Сберанк в Москве\" - ORG, \"Олимпиада 2014 в Сочи\" - EVT)\n",
    "- Если событие так же является местом (\"Он погиб в Сталинграде, незадолго до битвы\"), то выбирается тип LOC\n",
    "\n",
    "**Текст для анализа:**\n",
    "{document_text}\n",
    "\n",
    "**Формат ответа:**\n",
    "Перечисли найденные сущности в формате:\n",
    "- [Название сущности] -- [Тип];\n",
    "\n",
    "Пример:\n",
    "- Борис Джонсон -- PER;\n",
    "- Британия -- LOC;\n",
    "- Британии -- LOC;\n",
    "- Brexit -- EVT\"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c085b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример промпта для первой строки:\n",
      "==================================================\n",
      "Извлеки из **текста для анализа** все (необязательно уникальные) именованные сущности и классифицируй их по типам, опираясь на контекст и нижеуказанные инструкции.\n",
      "\n",
      "**Типы сущностей:**\n",
      "- PER (persons) - личности, имена людей (без прилежащих титулов), группы людей (\"русские\"; НО НЕ \"мусульмане\", т.к. нет конкретной объединяющей организации)\n",
      "- ORG (organizations) - организации, компании, учреждения, объединения\n",
      "- LOC (locations) - географические места, страны, города\n",
      "- EVT (events) - события, процессы, явления\n",
      "- PRO (products) - продукты, документы, произведения\n",
      "\n",
      "**Если равновероятными кажутся типы:**\n",
      "- ORG и PER, то должно быть выбрано PER;\n",
      "- ORG и PRO, то должно быть выбрано ORG.\n",
      "\n",
      "**Замечания:**\n",
      "- Сохраняй точную форму, регистр слов и количество вхождений сущностей как в оригинальном тексте. \n",
      "То есть, если сущность встречается в нескольких формах (Москва, Москвы), каждая форма должна быть в ответе.\n",
      "Однако одинаковые формы (Москва, Москва) повторять не надо.\n",
      "- Текст \"Премьер-министр Великобритании Тереза Мэй\" содержит LOC (Великобритании) и PER (Тереза Мэй)\n",
      "- Текст \"Церковь Св. Стефана в Стамбуле\" является целиком одной сущностью типа LOC\n",
      "- Расположение организации ORG и события EVT является частью их сущности (\"Сберанк в Москве\" - ORG, \"Олимпиада 2014 в Сочи\" - EVT)\n",
      "- Если событие так же является местом (\"Он погиб в Сталинграде, незадолго до битвы\"), то выбирается тип LOC\n",
      "\n",
      "**Текст для анализа:**\n",
      "Тереза Мэй рассчитывает усидеть в седле до завершения процедуры Brexit Тем не менее, по сведениям британских СМИ, на предстоящей в конце сентября конференции партии тори противники Мэй навяжут ей серьезный бой, из которого не факт, что она выйдет победителем. Фаворит букмекеров в качестве возможного сменщика нынешнего премьера, бывший министр иностранных дел Британии Борис Джонсон намерен выступить с альтернативным докладом, который не оставит камня на камне от взглядов главы правительства на условия \"брекзита\". С точки зрения Джонсона, \"Лондон обернул британскую конституцию поясом смертника и вручил детонатор Мишелю Барнье (главному переговорщику Брюсселя по \"брекзиту\". - От ред.)\". С этой метафорой и предстоит сражаться на конференции главе правительства Альбиона. Ради будущего торгового договора с единой Европой Лондон действительно согласился на множество уступок. Во-первых, он заплатит Брюсселю 39 миллиардов фунтов стерлингов. Во-вторых, будет выполнять законы ЕС. И, наконец, самое неприятное - от Британии требуют, чтобы она оставила Северную Ирландию в составе таможенного союза единой Европы. Это означает, по мнению Джонсона, что Британия может потерять Северную Ирландию, поскольку их союз в любой момент окажется в состоянии разорвать Брюссель. Понятно, что для гордых англичан такая потенциальная зависимость выглядит неприемлемой, да и терять территории Соединенного Королевства тоже не хочется. \"Мы сумели низвести великий британский брексит до двух ужасающих вариантов - или мы раскалываем наш союз, или вся страна навсегда обязана выполнять европейские законы\", - с присущим ему пафосом восклицает Джонсон, обращаясь к однопартийцам. Он убежден, что действия нынешнего премьера означают, что Британия \"направилась к статусу колонии\", не получив ничего взамен от единой Европы. Чем ответит Мэй на эти обвинения, схожие по составу с государственной изменой, не ясно. Судя по ее выступлению в четверг на экстренном саммите Евросоюза в Брюсселе, британский премьер рассчитывает на значительные уступки со стороны бывших коллег по единой Европе. И не прочь пошантажировать их возможным приходом Джонсона к власти на Альбионе: ведь в этом случае Брюсселю придется иметь дело с непредсказуемым, \"идейным\" переговорщиком, с которым практически невозможно договориться полюбовно. При всей \"конспирологичности\" нельзя полностью исключать версию, что экс-глава британского МИДа закулисно договорился с Мэй. И теперь действует по классической схеме боевиков - в то время как Борис Джонсон на публике изображает \"плохого полицейского\", Мэй в глазах Евросоюза выглядит белой и пушистой овечкой. Этот план, если он действительно существует, срабатывает на пятерку - перед началом открывшегося в среду экстренного саммита Евросоюза австрийский канцлер Себастьян Курц заявил, что \"брекзит\" без сделки был бы для всех проигрышным\", и \"значительно лучше договориться\". А европейские СМИ, ссылаясь на свои источники, утверждают: в Брюсселе хотят \"спасти Терезу\" от возможной отставки на конференции Консервативной партии и ради этого пойдут на уступки Лондону. В противном случае избежать хаоса, который возникнет, если Джонсон займет кресло британского премьера, избежать не удастся. А вариант триумфального возвращения Джонсона в правительство исключать нельзя - в британских букмекерских конторах критикующий договоренности с Евросоюзом бывший министр иностранных дел считается кандидатом - фаворитом на пост премьера. Кстати, Мэй тоже не прочь попугать своих европейских собеседников. В частности, она заявила, что в Лондоне уже готовятся к возможному выходу из состава Евросоюза по жесткому сценарию, без соглашения. \"По некоторым вопросам будут серьезные трудности и для Британии, и для Евросоюза\", - равнодушно констатировала премьер. Однако эксперты Международного валютного фонда предполагают, что в случае такого сценария Лондон потеряет значительно больше, чем единая Европа. Пока политики по обе стороны Ла-Манша пытаются взять друг друга \"на слабо\", британский бизнес создает запасы европейских товаров, включая лекарственные препараты. Со своей стороны Еврокомиссия готовит пакет экстренных законов в области регулирования финансовых рынков. Впрочем, даже договорившись с руководством Евросоюза об условиях выхода Британии и благополучно пережив в качестве премьера конференцию тори, Мэй не может быть уверенной, что далее все пройдет гладко. Дело в том, что соглашение Лондона и Брюсселя предстоит утвердить Европейскому и британскому парламентам. А там достаточно горячих голов, готовых в пух и прах разнести выстраданный на длительных переговорах компромисс, который в конечном итоге не понравится на 100 процентов ни британцам, ни европейцам. Так, оппозиционные британские лейбористы уже заявили, что проголосуют против любой сделки с Брюсселем, которую предложит Мэй. Столь же непримиримо к достигнутым премьером компромиссам настроена часть консерваторов. Так что утверждение сделки с Евросоюзом в британском парламенте может в принципе не состояться. При этом сценарии экономическое, да и политическое будущее Альбиона выглядит непредсказуемым и весьма туманным. Впрочем, к подобным капризам погоды британцам не привыкать...\n",
      "\n",
      "**Формат ответа:**\n",
      "Перечисли найденные сущности в формате:\n",
      "- [Название сущности] -- [Тип];\n",
      "\n",
      "Пример:\n",
      "- Борис Джонсон -- PER;\n",
      "- Британия -- LOC;\n",
      "- Британии -- LOC;\n",
      "- Brexit -- EVT\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Тестируем функцию на первой строке\n",
    "test_row = df.iloc[0]\n",
    "test_prompt = create_prompt_for_llm(test_row)\n",
    "print(\"Пример промпта для первой строки:\")\n",
    "print(\"=\"*50)\n",
    "print(test_prompt)\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f0e0b6",
   "metadata": {},
   "source": [
    "## Задание 4 (Получение и сохранение ответов от GigaChat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a68853",
   "metadata": {},
   "source": [
    "### Функции для реализации интерфейса в jupyter-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32446f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text: str, max_words: int = 300) -> List[str]:\n",
    "    \"\"\"\n",
    "    Разбивает текст на части по предложениям\n",
    "    \"\"\"\n",
    "    sentences = text.split('.')\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        if not sentence:\n",
    "            continue\n",
    "            \n",
    "        # Проверяем, не превысит ли добавление предложения лимит\n",
    "        test_chunk = current_chunk + \". \" + sentence if current_chunk else sentence\n",
    "        if len(test_chunk.split()) <= max_words:\n",
    "            current_chunk = test_chunk\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk + \".\")\n",
    "            current_chunk = sentence\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk + \".\")\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "def get_llm_response_interface(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Интерфейс для получения ответов от LLM и сохранения результатов\n",
    "    \"\"\"\n",
    "    # Создаем копию DataFrame и добавляем новые колонки\n",
    "    result_df = df.copy()\n",
    "    result_df['llm_entity'] = None\n",
    "    result_df['llm_answer'] = None\n",
    "    \n",
    "    # Получаем уникальные документы для обработки\n",
    "    unique_docs = df['document_id'].unique()\n",
    "    \n",
    "    print(f\"Найдено {len(unique_docs)} уникальных документов для обработки:\")\n",
    "    print(list(unique_docs))\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def parse_llm_response(response: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Парсит ответ LLM и возвращает список (entity, type)\n",
    "    \"\"\"\n",
    "    entities = []\n",
    "    lines = response.strip().split(';')\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "            \n",
    "        # Убираем тире в начале\n",
    "        if line.startswith('-'):\n",
    "            line = line[1:].strip()\n",
    "            \n",
    "        # Ищем паттерн \"сущность -- тип\"\n",
    "        if ' -- ' in line:\n",
    "            parts = line.split(' -- ', 1)\n",
    "            if len(parts) == 2:\n",
    "                entity = parts[0].strip()\n",
    "                entity_type = parts[1].strip()\n",
    "                if entity and entity_type:\n",
    "                    entities.append((entity, entity_type))\n",
    "    \n",
    "    return entities\n",
    "\n",
    "def process_document_chunked(doc_id: str, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Обрабатывает один документ по частям: показывает промпт и позволяет ввести ответ LLM\n",
    "    \"\"\"\n",
    "    # Получаем строки для данного документа\n",
    "    doc_rows = df[df['document_id'] == doc_id]\n",
    "    if doc_rows.empty:\n",
    "        raise Exception(f\"Документ {doc_id} не найден!\")\n",
    "    \n",
    "    first_row = doc_rows.iloc[0]\n",
    "\n",
    "    document_text = first_row['document_text']\n",
    "    \n",
    "    # Разбиваем текст на части\n",
    "    chunks = split_text_into_chunks(document_text, max_words=250)\n",
    "    \n",
    "    print(f\"Документ {doc_id} разбит на {len(chunks)} частей\")\n",
    "    \n",
    "    all_llm_entities = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        print(f\"\\n--- ЧАСТЬ {i}/{len(chunks)} ---\")\n",
    "        \n",
    "        # Создаем временную строку для части текста\n",
    "        chunk_row = first_row.copy()\n",
    "        chunk_row['document_text'] = chunk\n",
    "        \n",
    "        prompt = create_prompt_for_llm(chunk_row)\n",
    "        \n",
    "        print(\"ПРОМПТ:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(prompt)\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        print(f\"\\nВведите ответ для части {i} (пустая строка для завершения):\")\n",
    "        \n",
    "        llm_response_lines = []\n",
    "        while True:\n",
    "            line = input()\n",
    "            if line.strip() == '':\n",
    "                break\n",
    "            llm_response_lines.append(line)\n",
    "        \n",
    "        if llm_response_lines:\n",
    "            llm_response = '\\n'.join(llm_response_lines)\n",
    "            chunk_entities = parse_llm_response(llm_response)\n",
    "            all_llm_entities.extend(chunk_entities)\n",
    "    \n",
    "    # Удаляем дубликаты\n",
    "    unique_entities = []\n",
    "    seen = set()\n",
    "    for entity, entity_type in all_llm_entities:\n",
    "        entity_key = (entity.lower(), entity_type)\n",
    "        if entity_key not in seen:\n",
    "            unique_entities.append((entity, entity_type))\n",
    "            seen.add(entity_key)\n",
    "    \n",
    "    print(f\"\\nОбъединенный результат: {len(unique_entities)} уникальных сущностей\")\n",
    "    \n",
    "    # Сопоставляем найденные LLM сущности с золотым стандартом\n",
    "    gold_entities_list = doc_rows[doc_rows['entity'].notna()]['entity'].tolist()\n",
    "    matched_entities = set()\n",
    "    new_rows = []\n",
    "    \n",
    "    for llm_entity, llm_type in unique_entities:\n",
    "        # Ищем точное совпадение с золотым стандартом\n",
    "        match_found = False\n",
    "        for i, gold_entity in enumerate(gold_entities_list):\n",
    "            if llm_entity == gold_entity and gold_entity not in matched_entities:\n",
    "                # Найдено совпадение - обновляем соответствующую строку\n",
    "                mask = (df['document_id'] == doc_id) & (df['entity'] == gold_entity)\n",
    "                df.loc[mask, 'llm_entity'] = llm_entity\n",
    "                df.loc[mask, 'llm_answer'] = llm_type\n",
    "                matched_entities.add(gold_entity)\n",
    "                match_found = True\n",
    "                break\n",
    "        \n",
    "        if not match_found:\n",
    "            # LLM нашла новую сущность - создаем новую строку\n",
    "            new_row = {\n",
    "                'document_id': doc_id,\n",
    "                'document_text': first_row['document_text'],\n",
    "                'entity': None,\n",
    "                'gold_answer': None,\n",
    "                'llm_entity': llm_entity,\n",
    "                'llm_answer': llm_type\n",
    "            }\n",
    "            new_rows.append(new_row)\n",
    "    \n",
    "    \n",
    "    print(f\"\\nРезультат сохранен для документа {doc_id}\")\n",
    "    print(f\"LLM нашла {len(unique_entities)} сущностей\")\n",
    "    print(f\"Совпадений с золотым стандартом: {len(matched_entities)}\")\n",
    "    print(f\"Новых сущностей от LLM: {len(new_rows)}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Добавляем новые строки для сущностей, найденных только LLM\n",
    "    if new_rows:\n",
    "        new_df = pd.DataFrame(new_rows)\n",
    "        # Используем pd.concat для добавления новых строк\n",
    "        df = pd.concat([df, new_df], ignore_index=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_all_documents(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Последовательно обрабатывает все документы\n",
    "    \"\"\"\n",
    "    unique_docs = df['document_id'].unique()\n",
    "    \n",
    "    print(f\"Начинаем обработку {len(unique_docs)} документов...\")\n",
    "    print(\"Для каждого документа будет показан промпт, который нужно отправить в LLM\")\n",
    "    print(\"Затем введите полученный ответ\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    for i, doc_id in enumerate(unique_docs, 1):\n",
    "        print(f\"\\n[{i}/{len(unique_docs)}]\")\n",
    "        df = process_document_chunked(doc_id, df)\n",
    "        \n",
    "        if i < len(unique_docs):\n",
    "            ans = input(f\"\\nПродолжить с документом {i+1}? (y/n): \").strip().lower()\n",
    "            if ans.lower() != 'y':\n",
    "                print(\"Обработка остановлена.\")\n",
    "                break\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9cb7e5",
   "metadata": {},
   "source": [
    "### Печать пропмтов и получение ответов GigaChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25050b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 9 уникальных документов для обработки:\n",
      "['ru-10', 'ru-1000', 'ru-1001', 'ru-1002', 'ru-1003', 'ru-1004', 'ru-1006', 'ru-1011', 'ru-1017']\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем DataFrame для работы\n",
    "result_df = get_llm_response_interface(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c782c44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем обработку 9 документов...\n",
      "Для каждого документа будет показан промпт, который нужно отправить в LLM\n",
      "Затем введите полученный ответ\n",
      "\n",
      "\n",
      "\n",
      "[1/9]\n",
      "Документ ru-10 разбит на 3 частей\n",
      "\n",
      "--- ЧАСТЬ 1/3 ---\n",
      "ПРОМПТ:\n",
      "----------------------------------------\n",
      "Извлеки из **текста для анализа** все (необязательно уникальные) именованные сущности и классифицируй их по типам, опираясь на контекст и нижеуказанные инструкции.\n",
      "\n",
      "**Типы сущностей:**\n",
      "- PER (persons) - личности, имена людей (без прилежащих титулов), группы людей (\"русские\"; НО НЕ \"мусульмане\", т.к. нет конкретной объединяющей организации)\n",
      "- ORG (organizations) - организации, компании, учреждения, объединения\n",
      "- LOC (locations) - географические места, страны, города\n",
      "- EVT (events) - события, процессы, явления\n",
      "- PRO (products) - продукты, документы, произведения\n",
      "\n",
      "**Если равновероятными кажутся типы:**\n",
      "- ORG и PER, то должно быть выбрано PER;\n",
      "- ORG и PRO, то должно быть выбрано ORG.\n",
      "\n",
      "**Замечания:**\n",
      "- Сохраняй точную форму, регистр слов и количество вхождений сущностей как в оригинальном тексте. \n",
      "То есть, если сущность встречается в нескольких формах (Москва, Москвы), каждая форма должна быть в ответе.\n",
      "Однако одинаковые формы (Москва, Москва) повторять не надо.\n",
      "- Текст \"Премьер-министр Великобритании Тереза Мэй\" содержит LOC (Великобритании) и PER (Тереза Мэй)\n",
      "- Текст \"Церковь Св. Стефана в Стамбуле\" является целиком одной сущностью типа LOC\n",
      "- Расположение организации ORG и события EVT является частью их сущности (\"Сберанк в Москве\" - ORG, \"Олимпиада 2014 в Сочи\" - EVT)\n",
      "- Если событие так же является местом (\"Он погиб в Сталинграде, незадолго до битвы\"), то выбирается тип LOC\n",
      "\n",
      "**Текст для анализа:**\n",
      "Тереза Мэй рассчитывает усидеть в седле до завершения процедуры Brexit Тем не менее, по сведениям британских СМИ, на предстоящей в конце сентября конференции партии тори противники Мэй навяжут ей серьезный бой, из которого не факт, что она выйдет победителем. Фаворит букмекеров в качестве возможного сменщика нынешнего премьера, бывший министр иностранных дел Британии Борис Джонсон намерен выступить с альтернативным докладом, который не оставит камня на камне от взглядов главы правительства на условия \"брекзита\". С точки зрения Джонсона, \"Лондон обернул британскую конституцию поясом смертника и вручил детонатор Мишелю Барнье (главному переговорщику Брюсселя по \"брекзиту\". - От ред. )\". С этой метафорой и предстоит сражаться на конференции главе правительства Альбиона. Ради будущего торгового договора с единой Европой Лондон действительно согласился на множество уступок. Во-первых, он заплатит Брюсселю 39 миллиардов фунтов стерлингов. Во-вторых, будет выполнять законы ЕС. И, наконец, самое неприятное - от Британии требуют, чтобы она оставила Северную Ирландию в составе таможенного союза единой Европы. Это означает, по мнению Джонсона, что Британия может потерять Северную Ирландию, поскольку их союз в любой момент окажется в состоянии разорвать Брюссель. Понятно, что для гордых англичан такая потенциальная зависимость выглядит неприемлемой, да и терять территории Соединенного Королевства тоже не хочется. \"Мы сумели низвести великий британский брексит до двух ужасающих вариантов - или мы раскалываем наш союз, или вся страна навсегда обязана выполнять европейские законы\", - с присущим ему пафосом восклицает Джонсон, обращаясь к однопартийцам. Он убежден, что действия нынешнего премьера означают, что Британия \"направилась к статусу колонии\", не получив ничего взамен от единой Европы.\n",
      "\n",
      "**Формат ответа:**\n",
      "Перечисли найденные сущности в формате:\n",
      "- [Название сущности] -- [Тип];\n",
      "\n",
      "Пример:\n",
      "- Борис Джонсон -- PER;\n",
      "- Британия -- LOC;\n",
      "- Британии -- LOC;\n",
      "- Brexit -- EVT\n",
      "----------------------------------------\n",
      "\n",
      "Введите ответ для части 1 (пустая строка для завершения):\n",
      "\n",
      "--- ЧАСТЬ 2/3 ---\n",
      "ПРОМПТ:\n",
      "----------------------------------------\n",
      "Извлеки из **текста для анализа** все (необязательно уникальные) именованные сущности и классифицируй их по типам, опираясь на контекст и нижеуказанные инструкции.\n",
      "\n",
      "**Типы сущностей:**\n",
      "- PER (persons) - личности, имена людей (без прилежащих титулов), группы людей (\"русские\"; НО НЕ \"мусульмане\", т.к. нет конкретной объединяющей организации)\n",
      "- ORG (organizations) - организации, компании, учреждения, объединения\n",
      "- LOC (locations) - географические места, страны, города\n",
      "- EVT (events) - события, процессы, явления\n",
      "- PRO (products) - продукты, документы, произведения\n",
      "\n",
      "**Если равновероятными кажутся типы:**\n",
      "- ORG и PER, то должно быть выбрано PER;\n",
      "- ORG и PRO, то должно быть выбрано ORG.\n",
      "\n",
      "**Замечания:**\n",
      "- Сохраняй точную форму, регистр слов и количество вхождений сущностей как в оригинальном тексте. \n",
      "То есть, если сущность встречается в нескольких формах (Москва, Москвы), каждая форма должна быть в ответе.\n",
      "Однако одинаковые формы (Москва, Москва) повторять не надо.\n",
      "- Текст \"Премьер-министр Великобритании Тереза Мэй\" содержит LOC (Великобритании) и PER (Тереза Мэй)\n",
      "- Текст \"Церковь Св. Стефана в Стамбуле\" является целиком одной сущностью типа LOC\n",
      "- Расположение организации ORG и события EVT является частью их сущности (\"Сберанк в Москве\" - ORG, \"Олимпиада 2014 в Сочи\" - EVT)\n",
      "- Если событие так же является местом (\"Он погиб в Сталинграде, незадолго до битвы\"), то выбирается тип LOC\n",
      "\n",
      "**Текст для анализа:**\n",
      "Чем ответит Мэй на эти обвинения, схожие по составу с государственной изменой, не ясно. Судя по ее выступлению в четверг на экстренном саммите Евросоюза в Брюсселе, британский премьер рассчитывает на значительные уступки со стороны бывших коллег по единой Европе. И не прочь пошантажировать их возможным приходом Джонсона к власти на Альбионе: ведь в этом случае Брюсселю придется иметь дело с непредсказуемым, \"идейным\" переговорщиком, с которым практически невозможно договориться полюбовно. При всей \"конспирологичности\" нельзя полностью исключать версию, что экс-глава британского МИДа закулисно договорился с Мэй. И теперь действует по классической схеме боевиков - в то время как Борис Джонсон на публике изображает \"плохого полицейского\", Мэй в глазах Евросоюза выглядит белой и пушистой овечкой. Этот план, если он действительно существует, срабатывает на пятерку - перед началом открывшегося в среду экстренного саммита Евросоюза австрийский канцлер Себастьян Курц заявил, что \"брекзит\" без сделки был бы для всех проигрышным\", и \"значительно лучше договориться\". А европейские СМИ, ссылаясь на свои источники, утверждают: в Брюсселе хотят \"спасти Терезу\" от возможной отставки на конференции Консервативной партии и ради этого пойдут на уступки Лондону. В противном случае избежать хаоса, который возникнет, если Джонсон займет кресло британского премьера, избежать не удастся. А вариант триумфального возвращения Джонсона в правительство исключать нельзя - в британских букмекерских конторах критикующий договоренности с Евросоюзом бывший министр иностранных дел считается кандидатом - фаворитом на пост премьера. Кстати, Мэй тоже не прочь попугать своих европейских собеседников. В частности, она заявила, что в Лондоне уже готовятся к возможному выходу из состава Евросоюза по жесткому сценарию, без соглашения.\n",
      "\n",
      "**Формат ответа:**\n",
      "Перечисли найденные сущности в формате:\n",
      "- [Название сущности] -- [Тип];\n",
      "\n",
      "Пример:\n",
      "- Борис Джонсон -- PER;\n",
      "- Британия -- LOC;\n",
      "- Британии -- LOC;\n",
      "- Brexit -- EVT\n",
      "----------------------------------------\n",
      "\n",
      "Введите ответ для части 2 (пустая строка для завершения):\n",
      "\n",
      "--- ЧАСТЬ 3/3 ---\n",
      "ПРОМПТ:\n",
      "----------------------------------------\n",
      "Извлеки из **текста для анализа** все (необязательно уникальные) именованные сущности и классифицируй их по типам, опираясь на контекст и нижеуказанные инструкции.\n",
      "\n",
      "**Типы сущностей:**\n",
      "- PER (persons) - личности, имена людей (без прилежащих титулов), группы людей (\"русские\"; НО НЕ \"мусульмане\", т.к. нет конкретной объединяющей организации)\n",
      "- ORG (organizations) - организации, компании, учреждения, объединения\n",
      "- LOC (locations) - географические места, страны, города\n",
      "- EVT (events) - события, процессы, явления\n",
      "- PRO (products) - продукты, документы, произведения\n",
      "\n",
      "**Если равновероятными кажутся типы:**\n",
      "- ORG и PER, то должно быть выбрано PER;\n",
      "- ORG и PRO, то должно быть выбрано ORG.\n",
      "\n",
      "**Замечания:**\n",
      "- Сохраняй точную форму, регистр слов и количество вхождений сущностей как в оригинальном тексте. \n",
      "То есть, если сущность встречается в нескольких формах (Москва, Москвы), каждая форма должна быть в ответе.\n",
      "Однако одинаковые формы (Москва, Москва) повторять не надо.\n",
      "- Текст \"Премьер-министр Великобритании Тереза Мэй\" содержит LOC (Великобритании) и PER (Тереза Мэй)\n",
      "- Текст \"Церковь Св. Стефана в Стамбуле\" является целиком одной сущностью типа LOC\n",
      "- Расположение организации ORG и события EVT является частью их сущности (\"Сберанк в Москве\" - ORG, \"Олимпиада 2014 в Сочи\" - EVT)\n",
      "- Если событие так же является местом (\"Он погиб в Сталинграде, незадолго до битвы\"), то выбирается тип LOC\n",
      "\n",
      "**Текст для анализа:**\n",
      "\"По некоторым вопросам будут серьезные трудности и для Британии, и для Евросоюза\", - равнодушно констатировала премьер. Однако эксперты Международного валютного фонда предполагают, что в случае такого сценария Лондон потеряет значительно больше, чем единая Европа. Пока политики по обе стороны Ла-Манша пытаются взять друг друга \"на слабо\", британский бизнес создает запасы европейских товаров, включая лекарственные препараты. Со своей стороны Еврокомиссия готовит пакет экстренных законов в области регулирования финансовых рынков. Впрочем, даже договорившись с руководством Евросоюза об условиях выхода Британии и благополучно пережив в качестве премьера конференцию тори, Мэй не может быть уверенной, что далее все пройдет гладко. Дело в том, что соглашение Лондона и Брюсселя предстоит утвердить Европейскому и британскому парламентам. А там достаточно горячих голов, готовых в пух и прах разнести выстраданный на длительных переговорах компромисс, который в конечном итоге не понравится на 100 процентов ни британцам, ни европейцам. Так, оппозиционные британские лейбористы уже заявили, что проголосуют против любой сделки с Брюсселем, которую предложит Мэй. Столь же непримиримо к достигнутым премьером компромиссам настроена часть консерваторов. Так что утверждение сделки с Евросоюзом в британском парламенте может в принципе не состояться. При этом сценарии экономическое, да и политическое будущее Альбиона выглядит непредсказуемым и весьма туманным. Впрочем, к подобным капризам погоды британцам не привыкать.\n",
      "\n",
      "**Формат ответа:**\n",
      "Перечисли найденные сущности в формате:\n",
      "- [Название сущности] -- [Тип];\n",
      "\n",
      "Пример:\n",
      "- Борис Джонсон -- PER;\n",
      "- Британия -- LOC;\n",
      "- Британии -- LOC;\n",
      "- Brexit -- EVT\n",
      "----------------------------------------\n",
      "\n",
      "Введите ответ для части 3 (пустая строка для завершения):\n",
      "\n",
      "Объединенный результат: 0 уникальных сущностей\n",
      "\n",
      "Результат сохранен для документа ru-10\n",
      "LLM нашла 0 сущностей\n",
      "Совпадений с золотым стандартом: 0\n",
      "Новых сущностей от LLM: 0\n",
      "================================================================================\n",
      "Обработка остановлена.\n"
     ]
    }
   ],
   "source": [
    "# result_df = process_all_documents(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a722438f",
   "metadata": {},
   "source": [
    "### Сохранение/Загрузка Датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b578ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(df: pd.DataFrame, filename: str = 'llm_results_df'):\n",
    "    \"\"\"Сохраняет результаты в нескольких форматах\"\"\"\n",
    "    df.to_pickle(f'{filename}.pkl')\n",
    "    df.to_csv(f'{filename}.csv', index=False, encoding='utf-8')\n",
    "    print(f\"Результаты сохранены как {filename}.pkl и {filename}.csv\")\n",
    "\n",
    "\n",
    "def load_results(filename: str = 'llm_results') -> pd.DataFrame:\n",
    "    \"\"\"Загружает сохраненные результаты\"\"\"\n",
    "    try:\n",
    "        df = pd.read_pickle(f'{filename}.pkl')\n",
    "        print(f\"Загружен {filename}.pkl\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            df = pd.read_csv(f'{filename}.csv', encoding='utf-8')\n",
    "            print(f\"Загружен {filename}.csv\")\n",
    "            return df\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Файлы {filename}.pkl или {filename}.csv не найдены\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba31b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты сохранены как llm_results_df.pkl и llm_results_df.csv\n"
     ]
    }
   ],
   "source": [
    "# save_results(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b8bb4a",
   "metadata": {},
   "source": [
    "### Просмотр результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "220a0067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_text</th>\n",
       "      <th>entity</th>\n",
       "      <th>gold_answer</th>\n",
       "      <th>llm_entity</th>\n",
       "      <th>llm_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>EVT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Альбиона</td>\n",
       "      <td>LOC</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Альбионе</td>\n",
       "      <td>LOC</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Борис Джонсон</td>\n",
       "      <td>PER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Британии</td>\n",
       "      <td>LOC</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Британия</td>\n",
       "      <td>LOC</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Брюсселе</td>\n",
       "      <td>LOC</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Брюсселем</td>\n",
       "      <td>LOC</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Брюссель</td>\n",
       "      <td>LOC</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Брюсселю</td>\n",
       "      <td>LOC</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  document_id                                      document_text  \\\n",
       "0       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "1       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "2       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "3       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "4       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "5       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "6       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "7       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "8       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "9       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "\n",
       "          entity gold_answer llm_entity llm_answer  \n",
       "0         Brexit         EVT       None       None  \n",
       "1       Альбиона         LOC       None       None  \n",
       "2       Альбионе         LOC       None       None  \n",
       "3  Борис Джонсон         PER       None       None  \n",
       "4       Британии         LOC       None       None  \n",
       "5       Британия         LOC       None       None  \n",
       "6       Брюсселе         LOC       None       None  \n",
       "7      Брюсселем         LOC       None       None  \n",
       "8       Брюссель         LOC       None       None  \n",
       "9       Брюсселю         LOC       None       None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0660de",
   "metadata": {},
   "source": [
    "## Задание 5 (Подсчёт метрик)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5fac62",
   "metadata": {},
   "source": [
    "### Класс для подсчёта метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9747cbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class NERMetrics:\n",
    "    \"\"\"\n",
    "    Класс для вычисления метрик качества распознавания сущностей\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def extract_entity(label: str) -> str | None:\n",
    "        \"\"\"\n",
    "        Извлечение сущности из строки метки\n",
    "\n",
    "        Args:\n",
    "            label (str | None): метка, строка вида \"entity|type\"\n",
    "        Returns:\n",
    "            entity (str | None): строка сущности\n",
    "        \"\"\"\n",
    "        if pd.isna(label):\n",
    "            return None\n",
    "        return label.split('|')[0] if '|' in label else None\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_type(label: str) -> str | None:\n",
    "        \"\"\"\n",
    "        Извлечение типа сущности из строки метки\n",
    "\n",
    "        Args:\n",
    "            label (str | None): метка, строка вида \"entity|type\"\n",
    "        Returns:\n",
    "            type (str | None): строка типа сущности\n",
    "        \"\"\"\n",
    "        if pd.isna(label):\n",
    "            return None\n",
    "        return label.split('|')[1] if '|' in label else None\n",
    "\n",
    "    @staticmethod\n",
    "    def exact_match_score(gold: str, pred: str) -> float:\n",
    "        \"\"\"\n",
    "        Точное совпадение сущности и типа\n",
    "\n",
    "        Args:\n",
    "            gold (str | None): истинное значение, строка вида \"entity|type\"\n",
    "            pred (str | None): предсказанное значение, строка вида \"entity|type\"\n",
    "        Returns:\n",
    "            score (float): 1.0 если точное совпадение, 0.0 иначе\n",
    "        \"\"\"\n",
    "        if pd.isna(gold) and pd.isna(pred):\n",
    "            return 1.\n",
    "        if pd.isna(gold) or pd.isna(pred):\n",
    "            return 0.\n",
    "        return 1. if gold == pred else 0.\n",
    "    \n",
    "    @staticmethod\n",
    "    def boundary_match_score(gold: str, pred: str) -> float:\n",
    "        \"\"\"\n",
    "        Совпадение границ и формы сущности без учёта типа\n",
    "        \n",
    "        Args:\n",
    "            gold (str | None): истинное значение, строка вида \"entity|type\"\n",
    "            pred (str | None): предсказанное значение, строка вида \"entity|type\"\n",
    "        Returns:\n",
    "            score (float): 1.0 если строки одинаковы, 0.0 иначе\n",
    "        \"\"\"\n",
    "        if pd.isna(gold) and pd.isna(pred):\n",
    "            return 1.\n",
    "        if pd.isna(gold) or pd.isna(pred):\n",
    "            return 0.\n",
    "        \n",
    "        # Извлечение сущностей\n",
    "        gold_entity = NERMetrics.extract_entity(gold)\n",
    "        pred_entity = NERMetrics.extract_entity(pred)\n",
    "\n",
    "        if None in (gold_entity, pred_entity):\n",
    "            raise ValueError(f\"Gold ({gold_entity}) or prediction ({pred_entity}) has wrong format or None\")\n",
    "        \n",
    "        return 1. if gold_entity == pred_entity else 0.\n",
    "    \n",
    "    @staticmethod\n",
    "    def partial_match_levenshtein(gold: str, pred: str) -> float:\n",
    "        \"\"\"\n",
    "        Частичное совпадение границ и формы сущности (расстояние Левенштейна),\n",
    "        без учёта типа\n",
    "    \n",
    "        Args:\n",
    "            gold (str | None): истинное значение, строка вида \"entity|type\"\n",
    "            pred (str | None): предсказанное значение, строка вида \"entity|type\"\n",
    "        Returns:\n",
    "            score (float): нормализованное сходство от 0.0 до 1.0, где:\n",
    "                1.0 - полное сходство сущностей\n",
    "                0.0 - полное несовпадение\n",
    "        \"\"\"\n",
    "        if pd.isna(gold) and pd.isna(pred):\n",
    "            return 1.\n",
    "        if pd.isna(gold) or pd.isna(pred):\n",
    "            return 0.\n",
    "        \n",
    "        # Извлечение сущностей\n",
    "        gold_entity: str = NERMetrics.extract_entity(gold)  # type: ignore\n",
    "        pred_entity: str = NERMetrics.extract_entity(pred)  # type: ignore\n",
    "\n",
    "        if None in (gold_entity, pred_entity):\n",
    "            raise ValueError(f\"Gold ({gold_entity}) or prediction ({pred_entity}) has wrong format or None\")\n",
    "        \n",
    "        if gold_entity == pred_entity:\n",
    "            return 1.\n",
    "        \n",
    "        # Вычисляем расстояние Левенштейна\n",
    "        distance = NERMetrics.levenshtein_distance(gold_entity, pred_entity)\n",
    "        max_len = max(len(gold_entity), len(pred_entity))\n",
    "\n",
    "        # Нормализованное расстояние\n",
    "        return max(0., 1. - distance / max_len)\n",
    "\n",
    "    @staticmethod\n",
    "    def levenshtein_distance(s1: str, s2: str) -> float:\n",
    "        \"\"\"\n",
    "        Вычисляет модифицированное расстояние Левенштейна между двумя строками\n",
    "        (несовпадение регистра даёт штраф 0.5)\n",
    "        \n",
    "        Args:\n",
    "            s1 (str): первая строка\n",
    "            s2 (str): вторая строка\n",
    "        Returns:\n",
    "            distance (float): минимальное количество операций (вставка, удаление, замена)\n",
    "                для преобразования s1 в s2. Смена регистра стоит 0.5 вместо 1.0\n",
    "        \"\"\"\n",
    "\n",
    "        if len(s1) < len(s2):\n",
    "            return NERMetrics.levenshtein_distance(s2, s1)\n",
    "        \n",
    "        if len(s2) == 0:\n",
    "            return len(s1)\n",
    "        \n",
    "        # Динамическое программирование\n",
    "        previous_row = list(range(len(s2) + 1))\n",
    "        for i, c1 in enumerate(s1):\n",
    "            current_row = [i + 1.]\n",
    "            for j, c2 in enumerate(s2):\n",
    "                # Стоимость операций\n",
    "                insertions = previous_row[j + 1] + 1.      # вставка\n",
    "                deletions = current_row[j] + 1.            # удаление\n",
    "\n",
    "                if c1 == c2:\n",
    "                    cost = 0.\n",
    "                elif c1.lower() == c2.lower():  # Разный регистр\n",
    "                    cost = 0.5\n",
    "                else:\n",
    "                    cost = 1.0\n",
    "\n",
    "                substitutions = previous_row[j] + cost  # замена\n",
    "                current_row.append(min(insertions, deletions, substitutions))\n",
    "            previous_row = current_row\n",
    "        \n",
    "        return previous_row[-1]\n",
    "    \n",
    "    @staticmethod\n",
    "    def type_accuracy_score(gold: str, pred: str) -> float:\n",
    "        \"\"\"\n",
    "        Точность типа (совпадение или нет)\n",
    "\n",
    "        Args:\n",
    "            gold (str | None): истинное значение, строка вида \"entity|type\"\n",
    "            pred (str | None): предсказанное значение, строка вида \"entity|type\"\n",
    "        Returns:\n",
    "            score (float): 1.0 если типы совпадают, \n",
    "                          0.0 если типы не совпадают\n",
    "        \"\"\"\n",
    "\n",
    "        if pd.isna(gold) and pd.isna(pred):\n",
    "            return 1.\n",
    "        if pd.isna(gold) or pd.isna(pred):\n",
    "            return 0.\n",
    "        \n",
    "        gold_type = NERMetrics.extract_type(gold)\n",
    "        pred_type = NERMetrics.extract_type(pred)\n",
    "\n",
    "        if None in (gold_type, pred_type):\n",
    "            raise ValueError(f\"Gold ({gold_type}) or prediction ({pred_type}) has wrong format or None\")\n",
    "\n",
    "        return 1. if gold_type == pred_type else 0.\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_precision_recall_f1(tp: int, fp: int, fn: int) -> Tuple[float, float, float]:\n",
    "        \"\"\"\n",
    "        Вычисляет precision, recall и F1-score\n",
    "\n",
    "        Args:\n",
    "            tp: True Positives count\n",
    "            fp: False Positives count\n",
    "            fn: False Negatives count\n",
    "        Returns:\n",
    "            metrics : Tuple[precision, recall, f1]\n",
    "        \"\"\"\n",
    "        if tp + fp == 0:\n",
    "            return 0.0, 0.0, 0.0\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "        return precision, recall, f1\n",
    "\n",
    "    @staticmethod\n",
    "    def score_fn(gold: str, pred: str, type_importance: float=1.0) -> float:\n",
    "        \"\"\"\n",
    "        Основная функция подсчета метрики для NER\n",
    "        Вычисляет сходство найденной сущности от 0.0 до 1.0 на основе расстояния Левенштейна\n",
    "        Если же тип выбран неверно, то метрика домножается на \n",
    "        \n",
    "        Args:\n",
    "            gold: золотой стандарт в формате \"entity|type\" или None\n",
    "            pred: предсказание в формате \"entity|type\" или None\n",
    "            type_importance (от 0.0 до 1.0): коэффициент важности типа для метрики \n",
    "                (умножается на близость по Левенштейну)\n",
    "            \n",
    "        Returns:\n",
    "            score (float): оценка от 0.0 до 1.0, где 1.0 - точное совпадение\n",
    "        \"\"\"\n",
    "        wrong_type_penalty = type_importance * (1 - NERMetrics.type_accuracy_score(gold, pred))\n",
    "        return NERMetrics.boundary_match_score(gold, pred) * wrong_type_penalty\n",
    "\n",
    "    @staticmethod\n",
    "    def vectorized_ner_evaluation(df: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        Векторизованное вычисление метрик NER для DataFrame\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame с колонками 'entity', 'gold_answer', 'llm_entity', 'llm_answer'\n",
    "\n",
    "        Returns:\n",
    "            metrics_info (dict): словарь с полученными метриками\n",
    "        \"\"\"\n",
    "        # Подготовка данных - объединение entity и type\n",
    "        def combine_entity_type(entity, entity_type):\n",
    "            if pd.isna(entity) or pd.isna(entity_type):\n",
    "                return None\n",
    "            return f\"{entity}|{entity_type}\"\n",
    "\n",
    "        # Векторизованное объединение\n",
    "        gold_combined = df.apply(lambda row: combine_entity_type(row['entity'], row['gold_answer']), axis=1)  # type: ignore\n",
    "        pred_combined = df.apply(lambda row: combine_entity_type(row['llm_entity'], row['llm_answer']), axis=1)  # type: ignore\n",
    "        \n",
    "        # Векторизованное вычисление метрик\n",
    "        exact_scores = np.vectorize(NERMetrics.exact_match_score)(gold_combined, pred_combined)\n",
    "        boundary_scores = np.vectorize(NERMetrics.boundary_match_score)(gold_combined, pred_combined)\n",
    "        partial_scores = np.vectorize(NERMetrics.partial_match_levenshtein)(gold_combined, pred_combined)\n",
    "        type_scores = np.vectorize(NERMetrics.type_accuracy_score)(gold_combined, pred_combined)\n",
    "\n",
    "        # Вектора булевых занчений наличия сущности\n",
    "        gold_has_entity = ~pd.isna(gold_combined)\n",
    "        pred_has_entity = ~pd.isna(pred_combined)\n",
    "\n",
    "        \"\"\" Подсчёт TP, FP, FN для разных метрик \"\"\"\n",
    "\n",
    "        # 1. Точное совпадение сущности и типа\n",
    "        exact_tp = np.sum(exact_scores == 1. & pred_has_entity & gold_has_entity)\n",
    "        exact_fp = np.sum(pred_has_entity & (exact_scores == 0.))\n",
    "        exact_fn = np.sum(gold_has_entity & (exact_scores == 0.))\n",
    "\n",
    "        # 2. Совпадение границ и форм сущностей (только entity)\n",
    "        boundary_tp = np.sum(boundary_scores == 1. & pred_has_entity & gold_has_entity)\n",
    "        boundary_fp = np.sum(pred_has_entity & (boundary_scores == 0.))\n",
    "        boundary_fn = np.sum(gold_has_entity & (boundary_scores == 0.))\n",
    "\n",
    "        # 3. Частичное совпадение (средний score)\n",
    "        partial_avg = np.mean(partial_scores)\n",
    "        \n",
    "        # 4. Точность типов (только при точном совпадении сущностей)        \n",
    "        boundary_match_mask = boundary_scores == 1.0  # Фильтруем только случаи, где границы сущностей совпадают\n",
    "        valid_type_scores = type_scores[boundary_match_mask]\n",
    "        type_accuracy = np.mean(valid_type_scores) if len(valid_type_scores) > 0 else 0.0\n",
    "\n",
    "        # Вычисляем precision, recall, F1\n",
    "        exact_precision, exact_recall, exact_f1 = \\\n",
    "            NERMetrics.compute_precision_recall_f1(exact_tp, exact_fp, exact_fn)\n",
    "        \n",
    "        boundary_precision, boundary_recall, boundary_f1 = \\\n",
    "            NERMetrics.compute_precision_recall_f1(boundary_tp, boundary_fp, boundary_fn)\n",
    "        \n",
    "        # Метрики по классам\n",
    "        class_metrics = {}\n",
    "        for entity_type in ['PER', 'ORG', 'LOC', 'EVT', 'PRO']:\n",
    "            # Фильтруем только данный класс\n",
    "            gold_class_mask = df['gold_answer'] == entity_type\n",
    "            pred_class_mask = df['llm_answer'] == entity_type\n",
    "            \n",
    "            class_tp = np.sum(gold_class_mask & pred_class_mask & (exact_scores == 1.0))\n",
    "            class_fp = np.sum(pred_class_mask & (exact_scores == 0.0))\n",
    "            class_fn = np.sum(gold_class_mask & (exact_scores == 0.0))\n",
    "            \n",
    "            class_precision, class_recall, class_f1 = \\\n",
    "                NERMetrics.compute_precision_recall_f1(class_tp, class_fp, class_fn)\n",
    "            \n",
    "            class_metrics[entity_type] = {\n",
    "                'precision': class_precision,\n",
    "                'recall': class_recall,\n",
    "                'f1': class_f1,\n",
    "                'gold_count': np.sum(gold_class_mask)\n",
    "            }\n",
    "        \n",
    "        # Macro F1\n",
    "        macro_f1 = np.mean([metrics['f1'] for metrics in class_metrics.values()])\n",
    "        \n",
    "        return {\n",
    "            # Общие метрики\n",
    "            'exact_match_precision': exact_precision,\n",
    "            'exact_match_recall': exact_recall,\n",
    "            'exact_match_f1': exact_f1,\n",
    "            'boundary_precision': boundary_precision,\n",
    "            'boundary_recall': boundary_recall,\n",
    "            'boundary_f1': boundary_f1,\n",
    "            'partial_match_avg_similarity': partial_avg,\n",
    "            'type_accuracy': type_accuracy,\n",
    "            'macro_f1': macro_f1,\n",
    "            \n",
    "            # Статистика\n",
    "            'total_entities_gold': np.sum(gold_has_entity),\n",
    "            'total_entities_pred': np.sum(pred_has_entity),\n",
    "            'exact_tp': int(exact_tp),\n",
    "            'exact_fp': int(exact_fp),\n",
    "            'exact_fn': int(exact_fn),\n",
    "            \n",
    "            # По классам\n",
    "            'class_metrics': class_metrics\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a1543b",
   "metadata": {},
   "source": [
    "### Тесты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2c1d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class TestNERMetrics(unittest.TestCase):\n",
    "    \"\"\"Юнит-тесты для класса NERMetrics\"\"\"\n",
    "    \n",
    "    def setUp(self):\n",
    "        \"\"\"Настройка тестовых данных\"\"\"\n",
    "        self.valid_gold = \"Москва|LOC\"\n",
    "        self.valid_pred = \"Москва|LOC\"\n",
    "        self.different_entity = \"Питер|LOC\"\n",
    "        self.different_type = \"Москва|PER\"\n",
    "        self.invalid_format = \"Москва\"\n",
    "        self.none_value = None\n",
    "    \n",
    "    def test_extract_entity(self):\n",
    "        \"\"\"Тестирование извлечения сущности\"\"\"\n",
    "        # Валидные случаи\n",
    "        self.assertEqual(NERMetrics.extract_entity(\"Москва|LOC\"), \"Москва\")\n",
    "        self.assertEqual(NERMetrics.extract_entity(\"Борис Джонсон|PER\"), \"Борис Джонсон\")\n",
    "        \n",
    "        # Граничные случаи\n",
    "        self.assertIsNone(NERMetrics.extract_entity(None))\n",
    "        self.assertIsNone(NERMetrics.extract_entity(\"Москва\"))  # нет разделителя\n",
    "        self.assertEqual(NERMetrics.extract_entity(\"|LOC\"), \"\")  # пустая сущность\n",
    "        \n",
    "        # Множественные разделители\n",
    "        self.assertEqual(NERMetrics.extract_entity(\"a|b|c\"), \"a\")\n",
    "    \n",
    "    def test_extract_type(self):\n",
    "        \"\"\"Тестирование извлечения типа\"\"\"\n",
    "        # Валидные случаи\n",
    "        self.assertEqual(NERMetrics.extract_type(\"Москва|LOC\"), \"LOC\")\n",
    "        self.assertEqual(NERMetrics.extract_type(\"Brexit|EVT\"), \"EVT\")\n",
    "        \n",
    "        # Граничные случаи\n",
    "        self.assertIsNone(NERMetrics.extract_type(None))\n",
    "        self.assertIsNone(NERMetrics.extract_type(\"Москва\"))  # нет разделителя\n",
    "        self.assertEqual(NERMetrics.extract_type(\"Москва|\"), \"\")  # пустой тип\n",
    "        \n",
    "        # Множественные разделители\n",
    "        self.assertEqual(NERMetrics.extract_type(\"a|b|c\"), \"b\")\n",
    "    \n",
    "    def test_exact_match_score(self):\n",
    "        \"\"\"Тестирование точного совпадения\"\"\"\n",
    "        # Точные совпадения\n",
    "        self.assertEqual(NERMetrics.exact_match_score(\"Москва|LOC\", \"Москва|LOC\"), 1.0)\n",
    "        self.assertEqual(NERMetrics.exact_match_score(None, None), 1.0)\n",
    "        \n",
    "        # Несовпадения\n",
    "        self.assertEqual(NERMetrics.exact_match_score(\"Москва|LOC\", \"Питер|LOC\"), 0.0)\n",
    "        self.assertEqual(NERMetrics.exact_match_score(\"Москва|LOC\", \"Москва|PER\"), 0.0)\n",
    "        self.assertEqual(NERMetrics.exact_match_score(\"Москва|LOC\", None), 0.0)\n",
    "        self.assertEqual(NERMetrics.exact_match_score(None, \"Москва|LOC\"), 0.0)\n",
    "    \n",
    "    def test_boundary_match_score(self):\n",
    "        \"\"\"Тестирование совпадения границ\"\"\"\n",
    "        # Совпадения границ\n",
    "        self.assertEqual(NERMetrics.boundary_match_score(\"Москва|LOC\", \"Москва|PER\"), 1.0)\n",
    "        self.assertEqual(NERMetrics.boundary_match_score(\"Москва|LOC\", \"Москва|ORG\"), 1.0)\n",
    "        \n",
    "        # Несовпадения границ\n",
    "        self.assertEqual(NERMetrics.boundary_match_score(\"Москва|LOC\", \"Питер|LOC\"), 0.0)\n",
    "        \n",
    "        # Граничные случаи\n",
    "        self.assertEqual(NERMetrics.boundary_match_score(None, None), 1.0)\n",
    "        self.assertEqual(NERMetrics.boundary_match_score(\"Москва|LOC\", None), 0.0)\n",
    "        \n",
    "        # Неверный формат должен вызывать исключение\n",
    "        with self.assertRaises(ValueError):\n",
    "            NERMetrics.boundary_match_score(\"Москва\", \"Питер|LOC\")\n",
    "    \n",
    "    def test_levenshtein_distance(self):\n",
    "        \"\"\"Тестирование расстояния Левенштейна\"\"\"\n",
    "        # Одинаковые строки\n",
    "        self.assertEqual(NERMetrics.levenshtein_distance(\"abc\", \"abc\"), 0.0)\n",
    "        \n",
    "        # Разный регистр (штраф 0.5)\n",
    "        self.assertEqual(NERMetrics.levenshtein_distance(\"ABC\", \"abc\"), 1.5)\n",
    "        \n",
    "        # Полная замена\n",
    "        self.assertEqual(NERMetrics.levenshtein_distance(\"abc\", \"def\"), 3.0)\n",
    "        \n",
    "        # Вставка/удаление\n",
    "        self.assertEqual(NERMetrics.levenshtein_distance(\"abc\", \"abcd\"), 1.0)\n",
    "        self.assertEqual(NERMetrics.levenshtein_distance(\"abcd\", \"abc\"), 1.0)\n",
    "        \n",
    "        # Пустая строка\n",
    "        self.assertEqual(NERMetrics.levenshtein_distance(\"\", \"abc\"), 3.0)\n",
    "        self.assertEqual(NERMetrics.levenshtein_distance(\"abc\", \"\"), 3.0)\n",
    "    \n",
    "    def test_partial_match_levenshtein(self):\n",
    "        \"\"\"Тестирование частичного совпадения\"\"\"\n",
    "        # Точное совпадение\n",
    "        self.assertEqual(NERMetrics.partial_match_levenshtein(\"Москва|LOC\", \"Москва|PER\"), 1.0)\n",
    "        \n",
    "        # Частичное совпадение\n",
    "        score = NERMetrics.partial_match_levenshtein(\"Москва|LOC\", \"Москвы|PER\")\n",
    "        self.assertGreater(score, 0.5)  # должно быть достаточно высоким\n",
    "        self.assertLess(score, 1.0)\n",
    "        \n",
    "        # Полное несовпадение\n",
    "        score = NERMetrics.partial_match_levenshtein(\"Москва|LOC\", \"Лондон|PER\")\n",
    "        self.assertLess(score, 0.5)  # должно быть низким\n",
    "        \n",
    "        # Граничные случаи\n",
    "        self.assertEqual(NERMetrics.partial_match_levenshtein(None, None), 1.0)\n",
    "        self.assertEqual(NERMetrics.partial_match_levenshtein(\"Москва|LOC\", None), 0.0)\n",
    "    \n",
    "    def test_type_accuracy_score(self):\n",
    "        \"\"\"Тестирование точности типов\"\"\"\n",
    "        # Совпадение типов\n",
    "        self.assertEqual(NERMetrics.type_accuracy_score(\"Москва|LOC\", \"Питер|LOC\"), 1.0)\n",
    "        \n",
    "        # Несовпадение типов\n",
    "        self.assertEqual(NERMetrics.type_accuracy_score(\"Москва|LOC\", \"Москва|PER\"), 0.0)\n",
    "        \n",
    "        # Граничные случаи\n",
    "        self.assertEqual(NERMetrics.type_accuracy_score(None, None), 1.0)\n",
    "        self.assertEqual(NERMetrics.type_accuracy_score(\"Москва|LOC\", None), 0.0)\n",
    "        \n",
    "        # Неверный формат\n",
    "        with self.assertRaises(ValueError):\n",
    "            NERMetrics.type_accuracy_score(\"Москва\", \"Питер|LOC\")\n",
    "    \n",
    "    def test_compute_precision_recall_f1(self):\n",
    "        \"\"\"Тестирование вычисления precision, recall, F1\"\"\"\n",
    "        # Нормальный случай\n",
    "        precision, recall, f1 = NERMetrics.compute_precision_recall_f1(tp=8, fp=2, fn=3)\n",
    "        self.assertAlmostEqual(precision, 0.8)  # 8/(8+2)\n",
    "        self.assertAlmostEqual(recall, 8/11)    # 8/(8+3)\n",
    "        expected_f1 = 2 * precision * recall / (precision + recall)\n",
    "        self.assertAlmostEqual(f1, expected_f1)\n",
    "        \n",
    "        # Нулевой случай\n",
    "        precision, recall, f1 = NERMetrics.compute_precision_recall_f1(tp=0, fp=0, fn=5)\n",
    "        self.assertEqual(precision, 0.0)\n",
    "        self.assertEqual(recall, 0.0)\n",
    "        self.assertEqual(f1, 0.0)\n",
    "    \n",
    "    def test_score_fn(self):\n",
    "        \"\"\"Тестирование основной функции score_fn\"\"\"\n",
    "        # При type_importance=1.0 (по умолчанию)\n",
    "        # Если типы не совпадают, то штраф = 1.0 * (1 - 0) = 1.0\n",
    "        # Результат = boundary_match * (1 - штраф) = boundary_match * 0 = 0\n",
    "        score = NERMetrics.score_fn(\"Москва|LOC\", \"Москва|PER\")\n",
    "        self.assertEqual(score, 0.0)\n",
    "        \n",
    "        # Если типы совпадают, штраф = 1.0 * (1 - 1) = 0\n",
    "        # Результат = boundary_match * (1 - 0) = boundary_match\n",
    "        score = NERMetrics.score_fn(\"Москва|LOC\", \"Москва|LOC\")\n",
    "        self.assertEqual(score, 1.0)\n",
    "        \n",
    "        # При type_importance=0.0 тип не важен\n",
    "        score = NERMetrics.score_fn(\"Москва|LOC\", \"Москва|PER\", type_importance=0.0)\n",
    "        self.assertEqual(score, 1.0)  # только boundary_match важен\n",
    "    \n",
    "    def test_vectorized_ner_evaluation(self):\n",
    "        \"\"\"Тестирование векторизованной оценки\"\"\"\n",
    "        # Создаем тестовый DataFrame\n",
    "        test_data = {\n",
    "            'document_id': ['doc1', 'doc1', 'doc2', 'doc2'],\n",
    "            'document_text': ['text1', 'text1', 'text2', 'text2'],\n",
    "            'entity': ['Москва', 'Путин', None, 'Brexit'],\n",
    "            'gold_answer': ['LOC', 'PER', None, 'EVT'],\n",
    "            'llm_entity': ['Москва', 'Путин', 'Лондон', None],\n",
    "            'llm_answer': ['LOC', 'PER', 'LOC', None]\n",
    "        }\n",
    "        df = pd.DataFrame(test_data)\n",
    "        \n",
    "        metrics = NERMetrics.vectorized_ner_evaluation(df)\n",
    "        \n",
    "        # Проверяем структуру результата\n",
    "        self.assertIn('exact_match_f1', metrics)\n",
    "        self.assertIn('boundary_f1', metrics)\n",
    "        self.assertIn('type_accuracy', metrics)\n",
    "        self.assertIn('class_metrics', metrics)\n",
    "        \n",
    "        # Проверяем, что метрики в разумных пределах\n",
    "        self.assertGreaterEqual(metrics['exact_match_f1'], 0.0)\n",
    "        self.assertLessEqual(metrics['exact_match_f1'], 1.0)\n",
    "        \n",
    "        # Проверяем метрики по классам\n",
    "        for entity_type in ['PER', 'ORG', 'LOC', 'EVT', 'PRO']:\n",
    "            self.assertIn(entity_type, metrics['class_metrics'])\n",
    "\n",
    "\n",
    "class TestVectorization(unittest.TestCase):\n",
    "    \"\"\"Тесты для проверки векторизации\"\"\"\n",
    "    \n",
    "    def test_vectorization_speedup(self):\n",
    "        \"\"\"Проверка, что векторизация действительно быстрее\"\"\"\n",
    "        import time\n",
    "        \n",
    "        # Создаем большой тестовый датасет\n",
    "        n_samples = 1000\n",
    "        test_data = {\n",
    "            'document_id': [f'doc{i//10}' for i in range(n_samples)],\n",
    "            'document_text': [f'text{i}' for i in range(n_samples)],\n",
    "            'entity': [f'Entity{i}' if i % 3 != 0 else None for i in range(n_samples)],\n",
    "            'gold_answer': [['PER', 'LOC', 'ORG'][i % 3] if i % 3 != 0 else None for i in range(n_samples)],\n",
    "            'llm_entity': [f'Entity{i}' if i % 4 != 0 else None for i in range(n_samples)],\n",
    "            'llm_answer': [['PER', 'LOC', 'ORG'][i % 3] if i % 4 != 0 else None for i in range(n_samples)]\n",
    "        }\n",
    "        df = pd.DataFrame(test_data)\n",
    "        \n",
    "        # Векторизованная версия\n",
    "        start_time = time.time()\n",
    "        metrics_vectorized = NERMetrics.vectorized_ner_evaluation(df)\n",
    "        vectorized_time = time.time() - start_time\n",
    "        \n",
    "        # Проверяем, что результат разумный\n",
    "        self.assertIsInstance(metrics_vectorized, dict)\n",
    "        self.assertIn('exact_match_f1', metrics_vectorized)\n",
    "        \n",
    "        print(f\"Векторизованная версия: {vectorized_time:.4f} секунд\")\n",
    "\n",
    "\n",
    "class TestEdgeCases(unittest.TestCase):\n",
    "    \"\"\"Тесты граничных случаев\"\"\"\n",
    "    \n",
    "    def test_empty_dataframe(self):\n",
    "        \"\"\"Тест пустого DataFrame\"\"\"\n",
    "        df = pd.DataFrame(columns=['entity', 'gold_answer', 'llm_entity', 'llm_answer'])\n",
    "        \n",
    "        # Не должно падать с ошибкой\n",
    "        metrics = NERMetrics.vectorized_ner_evaluation(df)\n",
    "        self.assertEqual(metrics['total_entities_gold'], 0)\n",
    "        self.assertEqual(metrics['total_entities_pred'], 0)\n",
    "    \n",
    "    def test_all_none_dataframe(self):\n",
    "        \"\"\"Тест DataFrame со всеми None\"\"\"\n",
    "        df = pd.DataFrame({\n",
    "            'entity': [None, None, None],\n",
    "            'gold_answer': [None, None, None],\n",
    "            'llm_entity': [None, None, None],\n",
    "            'llm_answer': [None, None, None]\n",
    "        })\n",
    "        \n",
    "        metrics = NERMetrics.vectorized_ner_evaluation(df)\n",
    "        self.assertEqual(metrics['total_entities_gold'], 0)\n",
    "        self.assertEqual(metrics['total_entities_pred'], 0)\n",
    "    \n",
    "    def test_unicode_entities(self):\n",
    "        \"\"\"Тест с Unicode сущностями\"\"\"\n",
    "        score = NERMetrics.exact_match_score(\"Мюнхен|LOC\", \"Мюнхен|LOC\")\n",
    "        self.assertEqual(score, 1.0)\n",
    "        \n",
    "        score = NERMetrics.partial_match_levenshtein(\"Мюнхен|LOC\", \"Мюнхене|LOC\")\n",
    "        self.assertGreater(score, 0.8)\n",
    "\n",
    "\n",
    "def run_tests():\n",
    "    \"\"\"Запуск всех тестов\"\"\"\n",
    "    # Создаем test suite\n",
    "    test_suite = unittest.TestSuite()\n",
    "    \n",
    "    # Добавляем все тестовые классы\n",
    "    test_classes = [TestNERMetrics, TestVectorization, TestEdgeCases]\n",
    "    \n",
    "    for test_class in test_classes:\n",
    "        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)\n",
    "        test_suite.addTests(tests)\n",
    "    \n",
    "    # Запускаем тесты\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    result = runner.run(test_suite)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afa57cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_boundary_match_score (__main__.TestNERMetrics.test_boundary_match_score)\n",
      "Тестирование совпадения границ ... ok\n",
      "test_compute_precision_recall_f1 (__main__.TestNERMetrics.test_compute_precision_recall_f1)\n",
      "Тестирование вычисления precision, recall, F1 ... ok\n",
      "test_exact_match_score (__main__.TestNERMetrics.test_exact_match_score)\n",
      "Тестирование точного совпадения ... ok\n",
      "test_extract_entity (__main__.TestNERMetrics.test_extract_entity)\n",
      "Тестирование извлечения сущности ... ok\n",
      "test_extract_type (__main__.TestNERMetrics.test_extract_type)\n",
      "Тестирование извлечения типа ... ok\n",
      "test_levenshtein_distance (__main__.TestNERMetrics.test_levenshtein_distance)\n",
      "Тестирование расстояния Левенштейна ... ok\n",
      "test_partial_match_levenshtein (__main__.TestNERMetrics.test_partial_match_levenshtein)\n",
      "Тестирование частичного совпадения ... ok\n",
      "test_score_fn (__main__.TestNERMetrics.test_score_fn)\n",
      "Тестирование основной функции score_fn ... FAIL\n",
      "test_type_accuracy_score (__main__.TestNERMetrics.test_type_accuracy_score)\n",
      "Тестирование точности типов ... ok\n",
      "test_vectorized_ner_evaluation (__main__.TestNERMetrics.test_vectorized_ner_evaluation)\n",
      "Тестирование векторизованной оценки ... ERROR\n",
      "test_vectorization_speedup (__main__.TestVectorization.test_vectorization_speedup)\n",
      "Проверка, что векторизация действительно быстрее ... ERROR\n",
      "test_all_none_dataframe (__main__.TestEdgeCases.test_all_none_dataframe)\n",
      "Тест DataFrame со всеми None ... ERROR\n",
      "test_empty_dataframe (__main__.TestEdgeCases.test_empty_dataframe)\n",
      "Тест пустого DataFrame ... ERROR\n",
      "test_unicode_entities (__main__.TestEdgeCases.test_unicode_entities)\n",
      "Тест с Unicode сущностями ... ok\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_vectorized_ner_evaluation (__main__.TestNERMetrics.test_vectorized_ner_evaluation)\n",
      "Тестирование векторизованной оценки\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py\", line 362, in na_logical_op\n",
      "    result = op(x, y)\n",
      "             ^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/roperator.py\", line 54, in rand_\n",
      "    return operator.and_(right, left)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py\", line 376, in na_logical_op\n",
      "    result = libops.scalar_binop(x, y, op)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pandas/_libs/ops.pyx\", line 180, in pandas._libs.ops.scalar_binop\n",
      "ValueError: Buffer dtype mismatch, expected 'Python object' but got 'bool'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_24719/3864631696.py\", line 174, in test_vectorized_ner_evaluation\n",
      "    metrics = NERMetrics.vectorized_ner_evaluation(df)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_24719/3638473604.py\", line 256, in vectorized_ner_evaluation\n",
      "    exact_tp = np.sum(exact_scores == 1. & pred_has_entity & gold_has_entity)\n",
      "                                      ~~~^~~~~~~~~~~~~~~~~\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/ops/common.py\", line 76, in new_method\n",
      "    return method(self, other)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/arraylike.py\", line 74, in __rand__\n",
      "    return self._logical_method(other, roperator.rand_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/series.py\", line 6141, in _logical_method\n",
      "    res_values = ops.logical_op(lvalues, rvalues, op)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py\", line 454, in logical_op\n",
      "    res_values = na_logical_op(lvalues, rvalues, op)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py\", line 385, in na_logical_op\n",
      "    raise TypeError(\n",
      "TypeError: Cannot perform 'rand_' with a dtyped [bool] array and scalar of type [bool]\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_vectorization_speedup (__main__.TestVectorization.test_vectorization_speedup)\n",
      "Проверка, что векторизация действительно быстрее\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py\", line 362, in na_logical_op\n",
      "    result = op(x, y)\n",
      "             ^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/roperator.py\", line 54, in rand_\n",
      "    return operator.and_(right, left)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py\", line 376, in na_logical_op\n",
      "    result = libops.scalar_binop(x, y, op)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pandas/_libs/ops.pyx\", line 180, in pandas._libs.ops.scalar_binop\n",
      "ValueError: Buffer dtype mismatch, expected 'Python object' but got 'bool'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_24719/3864631696.py\", line 212, in test_vectorization_speedup\n",
      "    metrics_vectorized = NERMetrics.vectorized_ner_evaluation(df)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_24719/3638473604.py\", line 256, in vectorized_ner_evaluation\n",
      "    exact_tp = np.sum(exact_scores == 1. & pred_has_entity & gold_has_entity)\n",
      "                                      ~~~^~~~~~~~~~~~~~~~~\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/ops/common.py\", line 76, in new_method\n",
      "    return method(self, other)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/arraylike.py\", line 74, in __rand__\n",
      "    return self._logical_method(other, roperator.rand_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/series.py\", line 6141, in _logical_method\n",
      "    res_values = ops.logical_op(lvalues, rvalues, op)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py\", line 454, in logical_op\n",
      "    res_values = na_logical_op(lvalues, rvalues, op)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py\", line 385, in na_logical_op\n",
      "    raise TypeError(\n",
      "TypeError: Cannot perform 'rand_' with a dtyped [bool] array and scalar of type [bool]\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_all_none_dataframe (__main__.TestEdgeCases.test_all_none_dataframe)\n",
      "Тест DataFrame со всеми None\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py\", line 362, in na_logical_op\n",
      "    result = op(x, y)\n",
      "             ^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/roperator.py\", line 54, in rand_\n",
      "    return operator.and_(right, left)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py\", line 376, in na_logical_op\n",
      "    result = libops.scalar_binop(x, y, op)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"pandas/_libs/ops.pyx\", line 180, in pandas._libs.ops.scalar_binop\n",
      "ValueError: Buffer dtype mismatch, expected 'Python object' but got 'bool'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_24719/3864631696.py\", line 243, in test_all_none_dataframe\n",
      "    metrics = NERMetrics.vectorized_ner_evaluation(df)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_24719/3638473604.py\", line 256, in vectorized_ner_evaluation\n",
      "    exact_tp = np.sum(exact_scores == 1. & pred_has_entity & gold_has_entity)\n",
      "                                      ~~~^~~~~~~~~~~~~~~~~\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/ops/common.py\", line 76, in new_method\n",
      "    return method(self, other)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/arraylike.py\", line 74, in __rand__\n",
      "    return self._logical_method(other, roperator.rand_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/series.py\", line 6141, in _logical_method\n",
      "    res_values = ops.logical_op(lvalues, rvalues, op)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py\", line 454, in logical_op\n",
      "    res_values = na_logical_op(lvalues, rvalues, op)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/pandas/core/ops/array_ops.py\", line 385, in na_logical_op\n",
      "    raise TypeError(\n",
      "TypeError: Cannot perform 'rand_' with a dtyped [bool] array and scalar of type [bool]\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_empty_dataframe (__main__.TestEdgeCases.test_empty_dataframe)\n",
      "Тест пустого DataFrame\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_24719/3864631696.py\", line 230, in test_empty_dataframe\n",
      "    metrics = NERMetrics.vectorized_ner_evaluation(df)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_24719/3638473604.py\", line 244, in vectorized_ner_evaluation\n",
      "    exact_scores = np.vectorize(NERMetrics.exact_match_score)(gold_combined, pred_combined)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py\", line 2544, in __call__\n",
      "    return self._call_as_normal(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py\", line 2537, in _call_as_normal\n",
      "    return self._vectorize_call(func=func, args=vargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py\", line 2622, in _vectorize_call\n",
      "    ufunc, otypes = self._get_ufunc_and_otypes(func=func, args=args)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/emil/Desktop/Projects/Тестовые задания/Sber NLP 25/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py\", line 2578, in _get_ufunc_and_otypes\n",
      "    raise ValueError('cannot call `vectorize` on size 0 inputs '\n",
      "ValueError: cannot call `vectorize` on size 0 inputs unless `otypes` is set\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_score_fn (__main__.TestNERMetrics.test_score_fn)\n",
      "Тестирование основной функции score_fn\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_24719/3864631696.py\", line 150, in test_score_fn\n",
      "    self.assertEqual(score, 0.0)\n",
      "AssertionError: 1.0 != 0.0\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 14 tests in 0.048s\n",
      "\n",
      "FAILED (failures=1, errors=4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=14 errors=4 failures=1>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Запускаем тесты\n",
    "run_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sber nlp 25-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
