{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5830d50b",
   "metadata": {},
   "source": [
    "# Тестовое задание в команду Data Science IDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f284dc0",
   "metadata": {},
   "source": [
    "## Формулировка задания"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceb0370",
   "metadata": {},
   "source": [
    "**Написать решение по извлечению сущностей из документов (новостных текстов)**\n",
    "\n",
    "**Датасет** -- семпл текстов с аннотациями русских новостей (источник: https://bsnlp.cs.helsinki.fi/bsnlp-2019/shared_task.html)\n",
    "\n",
    "**Интересующие сущности:**\n",
    "- *PER* - persons (личности)\n",
    "- *ORG* - organizations (организации)\n",
    "- *LOC* - locations (места)\n",
    "- *EVT* - events (события)\n",
    "- *PRO* - products (продукты и документы)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f9de87",
   "metadata": {},
   "source": [
    "Достаточно использовать *9 документов* про *брекзит* из семпла"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d61960",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37be8b1",
   "metadata": {},
   "source": [
    "**Описание задачи с точки зрения NLP**\n",
    "\n",
    "Это задача извлечения именованных сущностей из текст -- *Named Entity Recognition (NER)*. В данном случае мы занимаемся последовательной разметкой, классифицируя каждый токен как PER, ORG, LOC, EVT, PRO или не являющийся сущностью\n",
    "\n",
    "**Классические методы решения:**\n",
    "- Статистические методы: *Условные случайные поля (CRF)*, *Марковская модель максимальной энтропии (MEMM)*\n",
    "- Рекуррентные нейронные сети: *LSTM*, *BiLSTM* (часто с CRF слоем)\n",
    "- Энкодерные трансформеры: *BERT-like*\n",
    "\n",
    "**LLM методы:**\n",
    "- *Zero-shot/Few-shot* подходы (GPT, в т.ч. *GigaChat*)\n",
    "- Промты с инструкциями для GPT-моделей\n",
    "- *Fine-tuning* на обучающей выборке\n",
    "- *Chain-of-Thought (CoT)* промпты для размышления перед определением сущности\n",
    "\n",
    "**Метрики качества:**\n",
    "- *Precision, Recall и F1-score* для найденных сущностей (верные границы), **без учета типа сущности**\n",
    "- *Precision, Recall и F1-score* для **точного совпадения** (границы + тип сущности)\n",
    "- Эти же метрики с *частичным совпадением границ*\n",
    "- Эти же метрики для каждого отдельного класса (для выявления, с какими типами сущностей у модели проблемы). Macro-F1\n",
    "\n",
    "- Можно добавить *accuracy* лемматизации каждой верно найденной сущности (для задачи из оригинального соревнования)\n",
    "- *Inference time* (в данном случае зависит от провайдера GigaChat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e51aea1",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "738f356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd1dcc1",
   "metadata": {},
   "source": [
    "### Чтение датасета в pandas DataFrame с обязательными колонками \"document_id\", \"document_text\", \"entity\", \"gold_answer\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578b9bee",
   "metadata": {},
   "source": [
    "#### Функция для извлечения данных и формирования DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e4d52ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bsnlp_data(data_dir: str='sample_pl_cs_ru_bg', lang: str=\"ru\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Считывание данных соревнования из папок raw/ru и annotated/ru и преобразует в\n",
    "    требуемый формат pd.DataFrame: [\"document_id\", \"document_text\", \"entity\", \"gold_answer\"]\n",
    "    \"\"\"\n",
    "    raw_dir = pathlib.Path(data_dir) / 'raw' / lang\n",
    "    annotated_dir = pathlib.Path(data_dir) / 'annotated' / lang\n",
    "\n",
    "    documents_desc: List[dict] = []\n",
    "\n",
    "    # Raw файлы\n",
    "    for raw_file in raw_dir.glob('*.txt'):\n",
    "        with open(raw_file, encoding=\"utf-8\") as f:\n",
    "            lines: List[str] = f.readlines()\n",
    "\n",
    "        assert len(lines) >= 5, f\"File \\\"{str(raw_file)}\\\" contains less than 5 lines\"\n",
    "\n",
    "        document_id = lines[0].strip()\n",
    "        language = lines[1].strip()\n",
    "        date = lines[2].strip()\n",
    "        url = lines[3].strip()\n",
    "        title = lines[4].strip()\n",
    "        content = ' '.join([line.strip() for line in lines[5:] if line.strip()])\n",
    "        document_text = title + ' ' + content\n",
    "\n",
    "        # Ищем соответствующий аннотированный файл\n",
    "        annotation_file = annotated_dir / f\"{raw_file.stem}.out\"\n",
    "\n",
    "        assert annotation_file.exists(), \\\n",
    "            f\"Annotation file \\\"{str(annotation_file)}\\\" corresponding to raw file \\\"{str(raw_file)}\\\" does not exist\"\n",
    "        \n",
    "        # Читаем аннотации\n",
    "        with open(annotation_file, encoding='utf-8') as f:\n",
    "            annotation_lines = f.readlines()\n",
    "\n",
    "        assert len(annotation_lines) > 0, f\"Annotation file \\\"{str(annotation_file)}\\\" is empty\"\n",
    "        annotation_doc_id = annotation_lines[0].strip()\n",
    "\n",
    "        assert document_id == annotation_doc_id, \"Raw and Annotated doc ids do not match: \" \\\n",
    "                                                f\"{document_id}, {annotation_doc_id}\"\n",
    "\n",
    "        entities_found = []\n",
    "\n",
    "        for line in annotation_lines[1:]:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                columns = line.split('\\t')\n",
    "                assert len(columns) == 4\n",
    "\n",
    "                entity_text, entity_text_lemmatized, entity_type, entity_id = columns\n",
    "\n",
    "                entities_found.append( (entity_text, entity_type) )\n",
    "        \n",
    "        for entity_text, entity_type in entities_found:\n",
    "            documents_desc.append({\n",
    "                'document_id': document_id,\n",
    "                'document_text': document_text,\n",
    "                'entity': entity_text,\n",
    "                'gold_answer': entity_type\n",
    "            })\n",
    "        if not entities_found:\n",
    "            documents_desc.append({\n",
    "                'document_id': document_id,\n",
    "                'document_text': document_text,\n",
    "                'entity': None,\n",
    "                'gold_answer': None\n",
    "            })\n",
    "        \n",
    "    return pd.DataFrame(documents_desc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96d312",
   "metadata": {},
   "source": [
    "#### Просмотр данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6516a236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_text</th>\n",
       "      <th>entity</th>\n",
       "      <th>gold_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>EVT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Альбиона</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Альбионе</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Борис Джонсон</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ru-10</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "      <td>Британии</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  document_id                                      document_text  \\\n",
       "0       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "1       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "2       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "3       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "4       ru-10  Тереза Мэй рассчитывает усидеть в седле до зав...   \n",
       "\n",
       "          entity gold_answer  \n",
       "0         Brexit         EVT  \n",
       "1       Альбиона         LOC  \n",
       "2       Альбионе         LOC  \n",
       "3  Борис Джонсон         PER  \n",
       "4       Британии         LOC  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_bsnlp_data()\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sber nlp 25-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
